"""
MinerU Tianshu RunPod Client - Complete Workflow
å¤©æ¢ RunPod å®¢æˆ·ç«¯ - å®Œæ•´å·¥ä½œæµç¨‹

æ¼”ç¤ºå®Œæ•´çš„æ–‡æ¡£è§£æå·¥ä½œæµç¨‹ï¼š
1. ä¸Šä¼ æ–‡ä»¶åˆ°é˜¿é‡Œäº‘ OSS
2. æäº¤ä»»åŠ¡åˆ° RunPod Serverless API
3. ç­‰å¾…ä»»åŠ¡å®Œæˆå¹¶è·å–ç»“æœ

æ¶æ„è¯´æ˜ï¼š
- RunPod Handler åªè´Ÿè´£é€ä¼ ä»»åŠ¡å‚æ•°ç»™ MinerU API æœåŠ¡å™¨
- æ–‡ä»¶ä¸‹è½½ã€è§£æç­‰ä¸šåŠ¡é€»è¾‘ç”± MinerU API æœåŠ¡å™¨å¤„ç†
- RunPod Handler ç­‰å¾… API æœåŠ¡å™¨å®Œæˆä»»åŠ¡åè¿”å›ç»“æœ
"""
import requests
import json
import time
import hashlib
from pathlib import Path
from typing import Dict, Any
from loguru import logger


class OSSUploader:
    """é˜¿é‡Œäº‘ OSS ä¸Šä¼ å™¨"""
    
    def __init__(self, access_key_id: str, access_key_secret: str, endpoint: str, bucket_name: str):
        """
        åˆå§‹åŒ– OSS ä¸Šä¼ å™¨
        
        Args:
            access_key_id: é˜¿é‡Œäº‘ Access Key ID
            access_key_secret: é˜¿é‡Œäº‘ Access Key Secret
            endpoint: OSS ç«¯ç‚¹ (å¦‚: oss-cn-beijing.aliyuncs.com)
            bucket_name: OSS Bucket åç§°
        """
        self.access_key_id = access_key_id
        self.access_key_secret = access_key_secret
        self.endpoint = endpoint
        self.bucket_name = bucket_name
        self._client = None
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ– OSS å®¢æˆ·ç«¯"""
        try:
            import oss2
            auth = oss2.Auth(self.access_key_id, self.access_key_secret)
            self._client = oss2.Bucket(auth, self.endpoint, self.bucket_name)
            logger.info(f"âœ… OSS client initialized: {self.bucket_name}")
        except ImportError:
            raise ImportError("è¯·å®‰è£… oss2 åº“: pip install oss2")
    
    def upload_file(self, local_path: str, object_name: str) -> str:
        """
        ä¸Šä¼ æ–‡ä»¶åˆ° OSS
        
        Args:
            local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            object_name: OSS ä¸­çš„å¯¹è±¡åç§°/è·¯å¾„
            
        Returns:
            ä¸Šä¼ åçš„å¯¹è±¡åç§°
        """
        local_file = Path(local_path)
        if not local_file.exists():
            raise FileNotFoundError(f"æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
        
        logger.info(f"ğŸ“¤ Uploading {local_file.name} to OSS://{object_name}")
        
        # ä¸Šä¼ æ–‡ä»¶åˆ° OSS
        with open(local_file, 'rb') as f:
            self._client.put_object(object_name, f)
        
        logger.info(f"âœ… Upload completed: {object_name}")
        return object_name
    
    def generate_object_name(self, local_path: str, prefix: str = "documents") -> str:
        """
        ç”Ÿæˆå¯¹è±¡å­˜å‚¨ä¸­çš„æ–‡ä»¶å
        
        Args:
            local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            prefix: å‰ç¼€ç›®å½•
            
        Returns:
            å¯¹è±¡åç§°
        """
        local_file = Path(local_path)
        
        # ç”ŸæˆåŸºäºæ–‡ä»¶å†…å®¹çš„å“ˆå¸Œå€¼ï¼Œé¿å…é‡å¤ä¸Šä¼ 
        with open(local_file, 'rb') as f:
            file_hash = hashlib.md5(f.read()).hexdigest()[:8]
        
        # æ„é€ å¯¹è±¡åç§°: prefix/filename_hash.ext
        object_name = f"{prefix}/{local_file.stem}_{file_hash}{local_file.suffix}"
        return object_name


class RunPodClient:
    """RunPod Serverless å®¢æˆ·ç«¯"""
    
    def __init__(self, endpoint_id: str, api_key: str):
        """
        åˆå§‹åŒ– RunPod å®¢æˆ·ç«¯
        
        Args:
            endpoint_id: RunPod Endpoint ID
            api_key: RunPod API Key
        """
        self.endpoint_id = endpoint_id
        self.api_key = api_key
        self.base_url = f"https://api.runpod.ai/v2/{endpoint_id}"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def submit_task(self, object_name: str, **kwargs) -> Dict[str, Any]:
        """
        æäº¤æ–‡æ¡£è§£æä»»åŠ¡
        
        Args:
            object_name: OSS å¯¹è±¡è·¯å¾„æˆ–å®Œæ•´ URL
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆfile_name, backend, lang, etc.ï¼‰
            
        Returns:
            RunPod å“åº”
        """
        payload = {
            "input": {
                "object_name": object_name,
                **kwargs
            }
        }
        
        logger.info(f"ğŸ“¤ Submitting task: {object_name}")
        
        response = requests.post(
            f"{self.base_url}/run",
            headers=self.headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            logger.info(f"âœ… Task submitted: {result.get('id')}")
            return result
        else:
            logger.error(f"âŒ Submission failed: {response.status_code} - {response.text}")
            response.raise_for_status()
    
    def get_task_status(self, task_id: str) -> Dict[str, Any]:
        """
        æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
        
        Args:
            task_id: RunPod ä»»åŠ¡ ID
            
        Returns:
            ä»»åŠ¡çŠ¶æ€å’Œç»“æœ
        """
        response = requests.get(
            f"{self.base_url}/status/{task_id}",
            headers=self.headers,
            timeout=10
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            logger.error(f"âŒ Status query failed: {response.status_code} - {response.text}")
            response.raise_for_status()
    
    def wait_for_completion(self, task_id: str, timeout: int = 300, poll_interval: int = 5) -> Dict[str, Any]:
        """
        ç­‰å¾…ä»»åŠ¡å®Œæˆ
        
        Args:
            task_id: RunPod ä»»åŠ¡ ID
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
            
        Returns:
            æœ€ç»ˆç»“æœ
        """
        start_time = time.time()
        
        logger.info(f"â³ Waiting for task {task_id} to complete...")
        
        while time.time() - start_time < timeout:
            try:
                status = self.get_task_status(task_id)
                
                if status.get('status') == 'COMPLETED':
                    logger.info(f"âœ… Task {task_id} completed")
                    return status
                elif status.get('status') == 'FAILED':
                    logger.error(f"âŒ Task {task_id} failed")
                    return status
                elif status.get('status') in ['IN_QUEUE', 'IN_PROGRESS']:
                    logger.info(f"ğŸ”„ Task {task_id} status: {status.get('status')}")
                else:
                    logger.info(f"ğŸ“Š Task {task_id} status: {status}")
                
                time.sleep(poll_interval)
                
            except Exception as e:
                logger.warning(f"âš ï¸  Status check failed: {e}")
                time.sleep(poll_interval)
        
        logger.error(f"â° Task {task_id} timed out after {timeout} seconds")
        return {"status": "TIMEOUT", "message": f"Task timed out after {timeout} seconds"}
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        payload = {
            "input": {
                "action": "health"
            }
        }
        
        response = requests.post(
            f"{self.base_url}/run",
            headers=self.headers,
            json=payload,
            timeout=10
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            response.raise_for_status()


def example_complete_workflow():
    """å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹ï¼šä¸Šä¼ æ–‡ä»¶ + å¤„ç†ä»»åŠ¡"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª Complete Workflow Example: Upload + Process")
    logger.info("=" * 60)
    
    # é…ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å®é™…å€¼ï¼‰
    ENDPOINT_ID = "your-endpoint-id"
    API_KEY = "your-api-key"
    
    # æœ¬åœ°æ–‡ä»¶è·¯å¾„
    local_file = "sample.pdf"  # è¯·ç¡®ä¿æ­¤æ–‡ä»¶å­˜åœ¨
    
    # OSS é…ç½®
    oss_config = {
        'access_key_id': 'your-access-key-id',
        'access_key_secret': 'your-access-key-secret',
        'endpoint': 'oss-cn-beijing.aliyuncs.com',
        'bucket_name': 'your-bucket-name'
    }
    
    try:
        # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶
        if not Path(local_file).exists():
            logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_file}")
            logger.info("è¯·å°†è¦å¤„ç†çš„æ–‡ä»¶é‡å‘½åä¸º 'sample.pdf' å¹¶æ”¾åœ¨å½“å‰ç›®å½•")
            return
        
        # 1. åˆå§‹åŒ– OSS ä¸Šä¼ å™¨
        logger.info("ğŸ”§ Initializing OSS uploader...")
        uploader = OSSUploader(**oss_config)
        
        # 2. ä¸Šä¼ æ–‡ä»¶åˆ° OSS
        logger.info("ğŸ“¤ Uploading file to OSS...")
        object_name = uploader.generate_object_name(local_file, prefix="documents")
        uploader.upload_file(local_file, object_name)
        
        # 3. åˆå§‹åŒ– RunPod å®¢æˆ·ç«¯
        logger.info("ğŸš€ Initializing RunPod client...")
        client = RunPodClient(ENDPOINT_ID, API_KEY)
        
        # 4. å¥åº·æ£€æŸ¥
        logger.info("ğŸ” Performing health check...")
        health = client.health_check()
        logger.info(f"Health status: {health}")
        
        # 5. æäº¤ä»»åŠ¡åˆ° RunPod
        logger.info("ğŸ“‹ Submitting task to RunPod...")
        task_result = client.submit_task(
            object_name=object_name,
            file_name=Path(local_file).name,
            backend="pipeline",
            lang="ch",
            method="auto",
            formula_enable=True,
            table_enable=True,
            priority=0
        )
        
        task_id = task_result.get('id')
        if not task_id:
            logger.error("âŒ Failed to get task ID")
            return
        
        # 6. ç­‰å¾…ä»»åŠ¡å®Œæˆ
        logger.info(f"â³ Waiting for task completion: {task_id}")
        final_result = client.wait_for_completion(task_id, timeout=300)
        
        # 7. å¤„ç†ç»“æœ
        if final_result.get('status') == 'COMPLETED':
            output = final_result.get('output', {})
            if output.get('success'):
                logger.info("ğŸ‰ Complete workflow finished successfully!")
                logger.info(f"   Original file: {local_file}")
                logger.info(f"   Object name: {object_name}")
                logger.info(f"   Parser used: {output.get('parser')}")
                logger.info(f"   File size: {output.get('file_size', 0)} bytes")
                logger.info(f"   Content length: {output.get('content_length')} characters")
                logger.info(f"   Processing time: {output.get('processing_time'):.2f}s")
                logger.info(f"   Result files: {len(output.get('result_files', []))}")
                logger.info(f"   Images: {output.get('image_count', 0)}")
                
                # ä¿å­˜è§£æç»“æœåˆ°æœ¬åœ°
                if output.get('content'):
                    output_file = f"output_{Path(local_file).stem}.md"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(output['content'])
                    logger.info(f"ğŸ“ Content saved to {output_file}")
                
                # æ˜¾ç¤ºç»“æœé¢„è§ˆ
                content = output.get('content', '')
                if content:
                    preview = content[:200] + "..." if len(content) > 200 else content
                    logger.info(f"ğŸ“„ Content preview:\n{preview}")
                    
            else:
                logger.error(f"âŒ Task failed: {output.get('error')}")
        else:
            logger.error(f"âŒ Task did not complete successfully: {final_result}")
    
    except Exception as e:
        logger.error(f"âŒ Complete workflow failed: {e}")
        import traceback
        logger.error(traceback.format_exc())


def example_batch_workflow():
    """æ‰¹é‡æ–‡ä»¶å¤„ç†ç¤ºä¾‹ï¼šä¸Šä¼ å¤šä¸ªæ–‡ä»¶å¹¶æ‰¹é‡å¤„ç†"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª Batch Workflow Example: Upload + Process Multiple Files")
    logger.info("=" * 60)
    
    # é…ç½®
    ENDPOINT_ID = "your-endpoint-id"
    API_KEY = "your-api-key"
    
    # æœ¬åœ°æ–‡ä»¶åˆ—è¡¨
    local_files = [
        {"path": "doc1.pdf", "lang": "ch"},
        {"path": "doc2.docx", "lang": "en"},
        {"path": "data.xlsx", "lang": "ch"},
    ]
    
    # OSS é…ç½®
    oss_config = {
        'access_key_id': 'your-access-key-id',
        'access_key_secret': 'your-access-key-secret',
        'endpoint': 'oss-cn-beijing.aliyuncs.com',
        'bucket_name': 'your-bucket-name'
    }
    
    try:
        # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
        uploader = OSSUploader(**oss_config)
        client = RunPodClient(ENDPOINT_ID, API_KEY)
        
        # 2. æ‰¹é‡ä¸Šä¼ æ–‡ä»¶
        uploaded_files = []
        logger.info("ğŸ“¤ Uploading files to OSS...")
        
        for file_info in local_files:
            local_path = file_info['path']
            
            if not Path(local_path).exists():
                logger.warning(f"âš ï¸  File not found, skipping: {local_path}")
                continue
            
            try:
                object_name = uploader.generate_object_name(local_path, prefix="batch")
                uploader.upload_file(local_path, object_name)
                
                uploaded_files.append({
                    'local_path': local_path,
                    'object_name': object_name,
                    'lang': file_info['lang']
                })
                
            except Exception as e:
                logger.error(f"âŒ Failed to upload {local_path}: {e}")
        
        if not uploaded_files:
            logger.error("âŒ No files uploaded successfully")
            return
        
        logger.info(f"âœ… Uploaded {len(uploaded_files)} files")
        
        # 3. æ‰¹é‡æäº¤ä»»åŠ¡
        tasks = []
        logger.info("ğŸ“‹ Submitting tasks to RunPod...")
        
        for file_info in uploaded_files:
            logger.info(f"ğŸ“¤ Submitting: {file_info['object_name']}")
            
            task_result = client.submit_task(
                object_name=file_info['object_name'],
                file_name=Path(file_info['local_path']).name,
                backend="pipeline",
                lang=file_info['lang'],
                formula_enable=True,
                table_enable=True
            )
            
            tasks.append({
                'id': task_result.get('id'),
                'local_path': file_info['local_path'],
                'object_name': file_info['object_name'],
                'submitted_at': time.time()
            })
            
            # é¿å…è¿‡å¿«æäº¤
            time.sleep(1)
        
        logger.info(f"âœ… Submitted {len(tasks)} tasks")
        
        # 4. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        completed_tasks = []
        logger.info("â³ Waiting for all tasks to complete...")
        
        for task in tasks:
            logger.info(f"â³ Waiting for {Path(task['local_path']).name}...")
            
            result = client.wait_for_completion(task['id'], timeout=300)
            
            completed_tasks.append({
                'local_path': task['local_path'],
                'object_name': task['object_name'],
                'task_id': task['id'],
                'result': result
            })
        
        # 5. æ±‡æ€»ç»“æœ
        logger.info("=" * 60)
        logger.info("ğŸ“Š Batch Processing Summary")
        logger.info("=" * 60)
        
        successful = 0
        failed = 0
        
        for task in completed_tasks:
            status = task['result'].get('status')
            file_name = Path(task['local_path']).name
            
            if status == 'COMPLETED':
                output = task['result'].get('output', {})
                if output.get('success'):
                    successful += 1
                    logger.info(f"âœ… {file_name}: {output.get('parser')} - {output.get('processing_time', 0):.1f}s")
                    
                    # ä¿å­˜ç»“æœ
                    if output.get('content'):
                        output_file = f"batch_output_{Path(task['local_path']).stem}.md"
                        with open(output_file, 'w', encoding='utf-8') as f:
                            f.write(output['content'])
                        logger.info(f"   ğŸ“ Saved to {output_file}")
                else:
                    failed += 1
                    logger.error(f"âŒ {file_name}: {output.get('error', 'Unknown error')}")
            else:
                failed += 1
                logger.error(f"âŒ {file_name}: {status}")
        
        logger.info(f"ğŸ“ˆ Final Results: {successful} successful, {failed} failed")
    
    except Exception as e:
        logger.error(f"âŒ Batch workflow failed: {e}")
        import traceback
        logger.error(traceback.format_exc())


def show_configuration_guide():
    """æ˜¾ç¤ºé…ç½®æŒ‡å—"""
    print("ğŸ“‹ é…ç½®æŒ‡å—")
    print("=" * 60)
    print()
    print("1. RunPod é…ç½®:")
    print("   - ENDPOINT_ID: ä½ çš„ RunPod Endpoint ID")
    print("   - API_KEY: ä½ çš„ RunPod API Key")
    print()
    print("2. é˜¿é‡Œäº‘ OSS é…ç½®:")
    print("   oss_config = {")
    print("       'access_key_id': 'your-access-key-id',")
    print("       'access_key_secret': 'your-access-key-secret',")
    print("       'endpoint': 'oss-cn-beijing.aliyuncs.com',")
    print("       'bucket_name': 'your-bucket-name'")
    print("   }")
    print()
    print("   å¸¸ç”¨ OSS ç«¯ç‚¹:")
    print("   - ååŒ—2ï¼ˆåŒ—äº¬ï¼‰: oss-cn-beijing.aliyuncs.com")
    print("   - åä¸œ1ï¼ˆæ­å·ï¼‰: oss-cn-hangzhou.aliyuncs.com")
    print("   - åä¸œ2ï¼ˆä¸Šæµ·ï¼‰: oss-cn-shanghai.aliyuncs.com")
    print("   - åå—1ï¼ˆæ·±åœ³ï¼‰: oss-cn-shenzhen.aliyuncs.com")
    print()
    print("3. å‡†å¤‡æ–‡ä»¶:")
    print("   - å•æ–‡ä»¶å¤„ç†: å°†æ–‡ä»¶å‘½åä¸º 'sample.pdf' æ”¾åœ¨å½“å‰ç›®å½•")
    print("   - æ‰¹é‡å¤„ç†: å°†æ–‡ä»¶å‘½åä¸º 'doc1.pdf', 'doc2.docx', 'data.xlsx' ç­‰")
    print()
    print("4. ä¾èµ–å®‰è£…:")
    print("   pip install requests loguru oss2")
    print()


if __name__ == '__main__':
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.remove()
    logger.add(lambda msg: print(msg, end=''), level="INFO", format="{time:HH:mm:ss} | {level} | {message}")
    
    print("ğŸš€ MinerU Tianshu RunPod Client - Complete Workflow")
    print("=" * 60)
    print()
    print("é€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹:")
    print("1. å®Œæ•´å·¥ä½œæµç¨‹ (æ¨è) - ä¸Šä¼ æ–‡ä»¶ + å¤„ç†ä»»åŠ¡")
    print("2. æ‰¹é‡å·¥ä½œæµç¨‹ - ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ + æ‰¹é‡å¤„ç†")
    print("3. æ˜¾ç¤ºé…ç½®æŒ‡å—")
    print()
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
    
    if choice == '1':
        print()
        print("ğŸ”„ å¯åŠ¨å®Œæ•´å·¥ä½œæµç¨‹...")
        print("è¯·ç¡®ä¿:")
        print("- å·²é…ç½® RunPod ENDPOINT_ID å’Œ API_KEY")
        print("- å·²é…ç½® OSS è¿æ¥ä¿¡æ¯")
        print("- å½“å‰ç›®å½•æœ‰ 'sample.pdf' æ–‡ä»¶")
        print()
        input("æŒ‰ Enter ç»§ç»­...")
        example_complete_workflow()
    elif choice == '2':
        print()
        print("ğŸ”„ å¯åŠ¨æ‰¹é‡å·¥ä½œæµç¨‹...")
        print("è¯·ç¡®ä¿:")
        print("- å·²é…ç½® RunPod ENDPOINT_ID å’Œ API_KEY")
        print("- å·²é…ç½® OSS è¿æ¥ä¿¡æ¯")
        print("- å½“å‰ç›®å½•æœ‰è¦å¤„ç†çš„æ–‡ä»¶ (doc1.pdf, doc2.docx, data.xlsx ç­‰)")
        print()
        input("æŒ‰ Enter ç»§ç»­...")
        example_batch_workflow()
    elif choice == '3':
        show_configuration_guide()
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        print()
        print("ğŸ’¡ æç¤º:")
        print("- é€‰é¡¹ 1: å¤„ç†å•ä¸ªæ–‡ä»¶çš„å®Œæ•´æµç¨‹")
        print("- é€‰é¡¹ 2: æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶çš„å®Œæ•´æµç¨‹")
        print("- é€‰é¡¹ 3: æŸ¥çœ‹è¯¦ç»†çš„é…ç½®è¯´æ˜")
