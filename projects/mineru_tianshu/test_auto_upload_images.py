#!/usr/bin/env python3
"""
å®Œæ•´ç¤ºä¾‹ï¼šæäº¤ PDF â†’ ç­‰å¾…å®Œæˆ â†’ è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ°å¯¹è±¡å­˜å‚¨ â†’ ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ° â†’ ä¿å­˜ç»“æœ

åŠŸèƒ½ï¼š
1. æäº¤æœ¬åœ° PDF æ–‡ä»¶
2. ç­‰å¾…ä»»åŠ¡å®Œæˆ
3. é€šè¿‡ API è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ°å¯¹è±¡å­˜å‚¨ï¼ˆupload_images=trueï¼‰
   - æ”¯æŒ MinIOã€è…¾è®¯äº‘ COSã€é˜¿é‡Œäº‘ OSS
   - å­˜å‚¨ç±»å‹åœ¨æœåŠ¡ç«¯é…ç½®ï¼ˆSTORAGE_TYPE ç¯å¢ƒå˜é‡ï¼‰
4. ä¿å­˜ Markdownï¼ˆåŒ…å«å¯¹è±¡å­˜å‚¨å›¾ç‰‡é“¾æ¥ï¼‰åˆ°æœ¬åœ°
5. ã€æ–°å¢ã€‘ä»å¯¹è±¡å­˜å‚¨ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ï¼ˆå¯é€‰ï¼ŒDOWNLOAD_IMAGES=Trueï¼‰
   - æå– Markdown ä¸­çš„å›¾ç‰‡ URL
   - ä¸‹è½½æ‰€æœ‰å›¾ç‰‡åˆ°æœ¬åœ° images/ ç›®å½•
   - æ›´æ–° Markdown ä¸­çš„å›¾ç‰‡é“¾æ¥ä¸ºæœ¬åœ°è·¯å¾„
   - ä¿å­˜æ›´æ–°åçš„ Markdown æ–‡ä»¶
6. å…¶ä»–æ–‡ä»¶ï¼ˆJSONã€PDF ç­‰ï¼‰ä¿ç•™åœ¨æœåŠ¡å™¨æœ¬åœ°è·¯å¾„

è¾“å‡ºæ–‡ä»¶ç»“æ„ï¼ˆDOWNLOAD_IMAGES=True æ—¶ï¼‰ï¼š
./auto_upload_output/
â”œâ”€â”€ {task_id}_{filename}.md       # åŸå§‹ Markdownï¼ˆå¯¹è±¡å­˜å‚¨é“¾æ¥ï¼‰
â”œâ”€â”€ {task_id}_metadata.json       # ä»»åŠ¡å…ƒæ•°æ®
â””â”€â”€ {task_id}/                    # ä»»åŠ¡ä¸“å±ç›®å½•
    â”œâ”€â”€ {filename}.md             # æ›´æ–°åçš„ Markdownï¼ˆæœ¬åœ°è·¯å¾„ï¼‰
    â””â”€â”€ images/                   # ä¸‹è½½çš„å›¾ç‰‡
        â”œâ”€â”€ image_000.png
        â”œâ”€â”€ image_001.png
        â””â”€â”€ ...

æœåŠ¡ç«¯ç¯å¢ƒå˜é‡è¦æ±‚ï¼ˆåœ¨ api_server.py æ‰€åœ¨æœåŠ¡å™¨é…ç½®ï¼‰ï¼š

MinIO/è…¾è®¯äº‘ COS:
  - STORAGE_TYPE: "minio" æˆ– "cos"
  - MINIO_ENDPOINT: Endpoint
  - MINIO_ACCESS_KEY: Access Key
  - MINIO_SECRET_KEY: Secret Key
  - MINIO_BUCKET: Bucket åç§°
  - MINIO_SECURE: "true" æˆ– "false"

é˜¿é‡Œäº‘ OSS:
  - STORAGE_TYPE: "oss"
  - OSS_ENDPOINT: Endpoint (å¦‚ oss-cn-shanghai.aliyuncs.com)
  - OSS_ACCESS_KEY: Access Key ID
  - OSS_SECRET_KEY: Access Key Secret
  - OSS_BUCKET: Bucket åç§°

å®¢æˆ·ç«¯é…ç½®ï¼ˆä»…å½“ä¸‹è½½ OSS ç§æœ‰ Bucket å›¾ç‰‡æ—¶éœ€è¦ï¼‰ï¼š
  - OSS_ACCESS_KEY: é˜¿é‡Œäº‘ Access Key ID
  - OSS_SECRET_KEY: é˜¿é‡Œäº‘ Access Key Secret
  
  å¦‚æœ OSS Bucket ä¸ºå…¬æœ‰è¯»ï¼Œåˆ™å®¢æˆ·ç«¯æ— éœ€é…ç½®å‡­è¯ã€‚
"""

import asyncio
import aiohttp
import json
import re
import os
from pathlib import Path
from typing import Optional, List, Tuple
from urllib.parse import urlparse

# ==================== é…ç½® ====================
API_BASE_URL = "https://facb9f32ae0653ea-8000.cn-south-1.gpu-instance.ppinfra.com"
LOCAL_PDF_PATH = "./1.pdf"  # è¦ä¸Šä¼ çš„ PDF æ–‡ä»¶è·¯å¾„
OUTPUT_DIR = "./auto_upload_output"  # æœ¬åœ°ä¿å­˜ç›®å½•

# ä»»åŠ¡å‚æ•°
BACKEND = "http-client"  # æˆ– "pipeline"
PARSE_METHOD = "auto"
LANG_LIST = ["zh"]

# ä¸‹è½½é€‰é¡¹
DOWNLOAD_IMAGES = True  # âœ… è®¾ç½®ä¸º True å¯ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°
                        # âŒ è®¾ç½®ä¸º False åªä½¿ç”¨å¯¹è±¡å­˜å‚¨é“¾æ¥

# ==================== è¾…åŠ©å‡½æ•° ====================

def extract_image_urls(md_content: str) -> List[Tuple[str, str]]:
    """
    ä» Markdown å†…å®¹ä¸­æå–å›¾ç‰‡ URL
    
    Args:
        md_content: Markdown å†…å®¹
        
    Returns:
        [(alt_text, image_url), ...] åˆ—è¡¨
    """
    image_urls = []
    
    # åŒ¹é… HTML img æ ‡ç­¾: <img src="url" alt="text">
    html_pattern = r'<img\s+src="([^"]+)"(?:\s+alt="([^"]*)")?[^>]*>'
    for match in re.finditer(html_pattern, md_content):
        url = match.group(1)
        alt_text = match.group(2) or ""
        image_urls.append((alt_text, url))
    
    # åŒ¹é… Markdown æ ¼å¼: ![alt](url)
    md_pattern = r'!\[([^\]]*)\]\(([^)]+)\)'
    for match in re.finditer(md_pattern, md_content):
        alt_text = match.group(1)
        url = match.group(2)
        # åªæ·»åŠ  HTTP/HTTPS URLï¼ˆè·³è¿‡ç›¸å¯¹è·¯å¾„ï¼‰
        if url.startswith(('http://', 'https://')):
            image_urls.append((alt_text, url))
    
    return image_urls


def detect_storage_type(url: str) -> str:
    """
    æ£€æµ‹ URL æ¥è‡ªå“ªç§å¯¹è±¡å­˜å‚¨
    
    Returns:
        'oss', 'cos', 'minio', 'unknown'
    """
    parsed = urlparse(url)
    hostname = parsed.hostname or ''
    
    if 'aliyuncs.com' in hostname or 'oss-' in hostname:
        return 'oss'
    elif 'myqcloud.com' in hostname or '.cos.' in hostname:
        return 'cos'
    else:
        return 'unknown'


def parse_oss_url(url: str) -> tuple:
    """
    è§£æé˜¿é‡Œäº‘ OSS URL
    
    Returns:
        (bucket, endpoint, object_key)
    """
    parsed = urlparse(url)
    hostname = parsed.hostname or ''
    
    # URL æ ¼å¼: https://bucket.oss-region.aliyuncs.com/path/to/object
    if '.oss-' in hostname:
        parts = hostname.split('.oss-')
        bucket = parts[0]
        endpoint = f"oss-{parts[1]}"
        object_key = parsed.path.lstrip('/')
        return bucket, endpoint, object_key
    
    return None, None, None


def download_from_oss(url: str, local_path: Path) -> bool:
    """
    ä½¿ç”¨ OSS SDK ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒç§æœ‰ Bucketï¼‰
    
    Args:
        url: OSS æ–‡ä»¶ URL
        local_path: æœ¬åœ°ä¿å­˜è·¯å¾„
        
    Returns:
        æ˜¯å¦ä¸‹è½½æˆåŠŸ
    """
    try:
        import oss2
    except ImportError:
        print(f"   âš ï¸  oss2 library not found, install it: pip install oss2")
        return False
    
    # è§£æ URL
    bucket_name, endpoint, object_key = parse_oss_url(url)
    if not all([bucket_name, endpoint, object_key]):
        print(f"   âš ï¸  Failed to parse OSS URL: {url}")
        return False
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–å‡­è¯
    access_key = os.getenv('OSS_ACCESS_KEY', '')
    secret_key = os.getenv('OSS_SECRET_KEY', '')
    
    if not access_key or not secret_key:
        print(f"   âš ï¸  OSS credentials not found in environment variables")
        print(f"       Set OSS_ACCESS_KEY and OSS_SECRET_KEY")
        return False
    
    try:
        # åˆ›å»º OSS å®¢æˆ·ç«¯
        auth = oss2.Auth(access_key, secret_key)
        bucket = oss2.Bucket(auth, endpoint, bucket_name)
        
        # ä¸‹è½½æ–‡ä»¶
        bucket.get_object_to_file(object_key, str(local_path))
        return True
        
    except Exception as e:
        print(f"   âŒ OSS download failed: {e}")
        return False


async def download_images_from_storage(
    session: aiohttp.ClientSession,
    md_content: str,
    output_dir: Path
) -> Tuple[str, int]:
    """
    ä»å¯¹è±¡å­˜å‚¨ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ï¼Œå¹¶æ›¿æ¢ Markdown ä¸­çš„é“¾æ¥
    æ”¯æŒï¼š
    - é˜¿é‡Œäº‘ OSSï¼ˆä½¿ç”¨ SDKï¼Œæ”¯æŒç§æœ‰ Bucketï¼‰
    - è…¾è®¯äº‘ COSï¼ˆHTTP ç›´æ¥ä¸‹è½½ï¼‰
    - MinIOï¼ˆHTTP ç›´æ¥ä¸‹è½½ï¼‰
    
    Args:
        session: aiohttp ä¼šè¯
        md_content: Markdown å†…å®¹
        output_dir: æœ¬åœ°è¾“å‡ºç›®å½•
        
    Returns:
        (updated_md_content, downloaded_count) å…ƒç»„
    """
    # åˆ›å»ºå›¾ç‰‡ç›®å½•
    images_dir = output_dir / "images"
    images_dir.mkdir(parents=True, exist_ok=True)
    
    # æå–å›¾ç‰‡ URL
    image_urls = extract_image_urls(md_content)
    
    if not image_urls:
        print("   â„¹ï¸  No images found in Markdown")
        return md_content, 0
    
    print(f"   ğŸ“¥ Found {len(image_urls)} images to download")
    
    downloaded_count = 0
    updated_content = md_content
    
    for alt_text, url in image_urls:
        try:
            # æ£€æµ‹å­˜å‚¨ç±»å‹
            storage_type = detect_storage_type(url)
            
            # ä» URL æå–æ–‡ä»¶å
            filename = Path(urlparse(url).path).name
            if not filename or '?' in filename:
                ext = '.png'  # é»˜è®¤æ‰©å±•å
                # ä» URL çŒœæµ‹æ‰©å±•å
                if url.endswith(('.jpg', '.jpeg')):
                    ext = '.jpg'
                elif url.endswith('.png'):
                    ext = '.png'
                elif url.endswith('.gif'):
                    ext = '.gif'
                filename = f"image_{downloaded_count:03d}{ext}"
            
            image_path = images_dir / filename
            image_data = None
            success = False
            
            # æ ¹æ®å­˜å‚¨ç±»å‹é€‰æ‹©ä¸‹è½½æ–¹å¼
            if storage_type == 'oss':
                # ä½¿ç”¨ OSS SDK ä¸‹è½½ï¼ˆæ”¯æŒç§æœ‰ Bucketï¼‰
                print(f"   ğŸ” Downloading from OSS: {filename}")
                success = download_from_oss(url, image_path)
                if success and image_path.exists():
                    file_size = image_path.stat().st_size
                    print(f"   âœ… Downloaded: {filename} ({file_size} bytes)")
            else:
                # ä½¿ç”¨ HTTP ç›´æ¥ä¸‹è½½ï¼ˆCOS/MinIO å…¬æœ‰è¯»ï¼‰
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                    if response.status == 200:
                        image_data = await response.read()
                        with open(image_path, 'wb') as f:
                            f.write(image_data)
                        success = True
                        print(f"   âœ… Downloaded: {filename} ({len(image_data)} bytes)")
                    else:
                        print(f"   âŒ Failed to download {url}: HTTP {response.status}")
            
            if success:
                # æ›¿æ¢ Markdown ä¸­çš„é“¾æ¥ä¸ºæœ¬åœ°è·¯å¾„
                local_path = f"images/{filename}"
                
                # æ›¿æ¢ HTML img æ ‡ç­¾
                html_old = f'<img src="{url}"'
                html_new = f'<img src="{local_path}"'
                updated_content = updated_content.replace(html_old, html_new)
                
                # æ›¿æ¢ Markdown æ ¼å¼
                md_old = f']({url})'
                md_new = f']({local_path})'
                updated_content = updated_content.replace(md_old, md_new)
                
                downloaded_count += 1
                
        except Exception as e:
            print(f"   âŒ Error downloading {url}: {e}")
    
    return updated_content, downloaded_count


# ==================== å®¢æˆ·ç«¯ ====================

class TianshuClient:
    """MinerU Tianshu API å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = API_BASE_URL):
        self.base_url = base_url.rstrip('/')
    
    async def submit_task(
        self,
        session: aiohttp.ClientSession,
        file_path: str,
        backend: str = "pipeline",
        parse_method: str = "auto",
        lang_list: list = None
    ) -> dict:
        """æäº¤ä»»åŠ¡"""
        if lang_list is None:
            lang_list = ["zh"]
        
        url = f"{self.base_url}/api/v1/tasks/submit"
        
        # å‡†å¤‡æ–‡ä»¶
        file_name = Path(file_path).name
        with open(file_path, 'rb') as f:
            file_data = f.read()
        
        # æ„å»ºè¡¨å•æ•°æ®
        form = aiohttp.FormData()
        form.add_field('file',
                      file_data,
                      filename=file_name,
                      content_type='application/pdf')
        form.add_field('backend', backend)
        form.add_field('parse_method', parse_method)
        for lang in lang_list:
            form.add_field('lang_list', lang)
        
        print(f"ğŸ“¤ Submitting task: {file_name}")
        print(f"   Backend: {backend}")
        print(f"   Parse method: {parse_method}")
        print(f"   Languages: {lang_list}")
        
        async with session.post(url, data=form) as resp:
            result = await resp.json()
            if result.get('success'):
                print(f"âœ… Task submitted successfully!")
                print(f"   Task ID: {result['task_id']}")
                return result
            else:
                raise Exception(f"Failed to submit task: {result}")
    
    async def get_task_status(
        self,
        session: aiohttp.ClientSession,
        task_id: str,
        upload_images: bool = False
    ) -> dict:
        """
        æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
        
        Args:
            task_id: ä»»åŠ¡ ID
            upload_images: æ˜¯å¦è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ° COS/MinIOï¼ˆå¦‚æœä¸º Trueï¼Œä¼šæ›¿æ¢ Markdown ä¸­çš„å›¾ç‰‡é“¾æ¥ï¼‰
        """
        url = f"{self.base_url}/api/v1/tasks/{task_id}"
        params = {'upload_images': str(upload_images).lower()}
        
        async with session.get(url, params=params) as resp:
            return await resp.json()
    
    async def wait_for_task(
        self,
        session: aiohttp.ClientSession,
        task_id: str,
        poll_interval: float = 2.0,
        timeout: float = 600.0
    ) -> dict:
        """
        ç­‰å¾…ä»»åŠ¡å®Œæˆ
        
        Returns:
            ä»»åŠ¡æœ€ç»ˆçŠ¶æ€ï¼ˆä¸åŒ…å«å›¾ç‰‡ä¸Šä¼ ï¼Œéœ€è¦å•ç‹¬è°ƒç”¨ get_task_status(upload_images=True)ï¼‰
        """
        print(f"â³ Waiting for task {task_id} to complete...")
        
        elapsed = 0.0
        while elapsed < timeout:
            result = await self.get_task_status(session, task_id, upload_images=False)
            status = result['status']
            
            if status == 'completed':
                print(f"âœ… Task completed!")
                return result
            elif status == 'failed':
                error = result.get('error_message', 'Unknown error')
                raise Exception(f"Task failed: {error}")
            elif status == 'cancelled':
                raise Exception("Task was cancelled")
            
            # æ˜¾ç¤ºè¿›åº¦
            print(f"   Status: {status} (elapsed: {elapsed:.1f}s)")
            
            await asyncio.sleep(poll_interval)
            elapsed += poll_interval
        
        raise TimeoutError(f"Task did not complete within {timeout}s")


# ==================== ä¸»å‡½æ•° ====================

async def main():
    """å®Œæ•´çš„å·¥ä½œæµç¨‹"""
    
    print("=" * 60)
    print("MinerU Tianshu - è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ°å¯¹è±¡å­˜å‚¨ç¤ºä¾‹")
    print("=" * 60)
    print()
    
    # æ£€æŸ¥ PDF æ–‡ä»¶
    if not Path(LOCAL_PDF_PATH).exists():
        print(f"âŒ PDF file not found: {LOCAL_PDF_PATH}")
        print(f"   Please update LOCAL_PDF_PATH in the script")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(OUTPUT_DIR)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    client = TianshuClient(API_BASE_URL)
    
    async with aiohttp.ClientSession() as session:
        # ==================== æ­¥éª¤ 1: æäº¤ä»»åŠ¡ ====================
        print("ğŸ“‹ Step 1: Submit task")
        print("-" * 60)
        
        result = await client.submit_task(
            session,
            file_path=LOCAL_PDF_PATH,
            backend=BACKEND,
            parse_method=PARSE_METHOD,
            lang_list=LANG_LIST
        )
        
        task_id = result['task_id']
        print()
        
        # ==================== æ­¥éª¤ 2: ç­‰å¾…ä»»åŠ¡å®Œæˆ ====================
        print("ğŸ“‹ Step 2: Wait for task completion")
        print("-" * 60)
        
        await client.wait_for_task(session, task_id)
        print()
        
        # ==================== æ­¥éª¤ 3: è·å–ç»“æœï¼ˆè‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ°å¯¹è±¡å­˜å‚¨ï¼‰====================
        print("ğŸ“‹ Step 3: Get results with auto image upload to storage")
        print("-" * 60)
        print("ğŸ–¼ï¸  Requesting API to upload images to object storage...")
        
        final_result = await client.get_task_status(
            session,
            task_id,
            upload_images=True  # ğŸ”‘ å…³é”®å‚æ•°ï¼šè‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ°å¯¹è±¡å­˜å‚¨
        )
        
        if not final_result.get('data'):
            print("âŒ No data returned. Task may have failed or results were cleaned up.")
            return
        
        data = final_result['data']
        md_content = data['content']
        md_filename = data['markdown_file']
        images_uploaded = data['images_uploaded']
        
        print(f"âœ… Results retrieved successfully!")
        print(f"   Markdown file: {md_filename}")
        print(f"   Content length: {len(md_content)} characters")
        print(f"   Images uploaded to storage: {images_uploaded}")
        print()
        
        # ==================== æ­¥éª¤ 4: ä¿å­˜åˆ°æœ¬åœ° ====================
        print("ğŸ“‹ Step 4: Save results to local")
        print("-" * 60)
        
        # ä¿å­˜ Markdownï¼ˆåŒ…å«å¯¹è±¡å­˜å‚¨å›¾ç‰‡é“¾æ¥ï¼‰
        local_md_path = output_dir / f"{task_id}_{md_filename}"
        with open(local_md_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        print(f"âœ… Saved Markdown to: {local_md_path}")
        
        # ä¿å­˜å®Œæ•´çš„ API å“åº”ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
        metadata_path = output_dir / f"{task_id}_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            # ä¸ä¿å­˜ contentï¼ˆå·²ç»ä¿å­˜ä¸º .md æ–‡ä»¶ï¼‰
            metadata = {k: v for k, v in final_result.items() if k != 'data'}
            metadata['data_info'] = {
                'markdown_file': md_filename,
                'content_length': len(md_content),
                'images_uploaded': images_uploaded
            }
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        print(f"âœ… Saved metadata to: {metadata_path}")
        print()
        
        # ==================== æ­¥éª¤ 5: ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ï¼ˆå¯é€‰ï¼‰====================
        images_downloaded = 0
        final_md_path = local_md_path
        
        if DOWNLOAD_IMAGES and images_uploaded:
            print("ğŸ“‹ Step 5: Download images from storage to local")
            print("-" * 60)
            print("ğŸ–¼ï¸  Downloading images from object storage...")
            
            # åˆ›å»ºä»»åŠ¡ä¸“å±è¾“å‡ºç›®å½•
            task_output_dir = output_dir / task_id
            task_output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¸‹è½½å›¾ç‰‡å¹¶æ›´æ–° Markdown å†…å®¹
            updated_md_content, images_downloaded = await download_images_from_storage(
                session,
                md_content,
                task_output_dir
            )
            
            if images_downloaded > 0:
                # ä¿å­˜æ›´æ–°åçš„ Markdownï¼ˆåŒ…å«æœ¬åœ°å›¾ç‰‡è·¯å¾„ï¼‰
                final_md_path = task_output_dir / md_filename
                with open(final_md_path, 'w', encoding='utf-8') as f:
                    f.write(updated_md_content)
                
                print(f"âœ… Downloaded {images_downloaded} images")
                print(f"âœ… Saved updated Markdown to: {final_md_path}")
                print(f"   Images directory: {task_output_dir / 'images'}")
            else:
                print("âš ï¸  No images downloaded")
            
            print()
        elif DOWNLOAD_IMAGES and not images_uploaded:
            print("â„¹ï¸  DOWNLOAD_IMAGES is True but no images were uploaded to storage")
            print("   Skipping image download step")
            print()
        
        # ==================== æ€»ç»“ ====================
        print("=" * 60)
        print("âœ… å®Œæˆï¼")
        print("=" * 60)
        print()
        print("ğŸ“ æœ¬åœ°æ–‡ä»¶ï¼š")
        
        if images_downloaded > 0:
            print(f"   â€¢ Markdown (å«æœ¬åœ°å›¾ç‰‡è·¯å¾„): {final_md_path}")
            print(f"   â€¢ å›¾ç‰‡ç›®å½•: {task_output_dir / 'images'} ({images_downloaded} å¼ å›¾ç‰‡)")
            print(f"   â€¢ åŸå§‹ Markdown (å«äº‘ç«¯é“¾æ¥): {local_md_path}")
        else:
            print(f"   â€¢ Markdown (å«å¯¹è±¡å­˜å‚¨å›¾ç‰‡é“¾æ¥): {local_md_path}")
        
        print(f"   â€¢ å…ƒæ•°æ®: {metadata_path}")
        print()
        
        print("ğŸ–¼ï¸  å›¾ç‰‡å­˜å‚¨ï¼š")
        if images_uploaded:
            print(f"   â€¢ äº‘ç«¯ï¼šæ‰€æœ‰å›¾ç‰‡å·²ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨ï¼ˆMinIO/COS/OSSï¼‰")
        if images_downloaded > 0:
            print(f"   â€¢ æœ¬åœ°ï¼šå·²ä¸‹è½½ {images_downloaded} å¼ å›¾ç‰‡åˆ°æœ¬åœ°")
            print(f"   â€¢ Markdown å›¾ç‰‡é“¾æ¥ï¼šæœ¬åœ°è·¯å¾„ (images/xxx.png)")
        elif DOWNLOAD_IMAGES:
            print(f"   â€¢ æœ¬åœ°ï¼šæœªä¸‹è½½å›¾ç‰‡ï¼ˆDOWNLOAD_IMAGES=True ä½†æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ï¼‰")
        else:
            print(f"   â€¢ æœ¬åœ°ï¼šæœªä¸‹è½½å›¾ç‰‡ï¼ˆDOWNLOAD_IMAGES=Falseï¼‰")
            print(f"   â€¢ Markdown å›¾ç‰‡é“¾æ¥ï¼šå¯¹è±¡å­˜å‚¨ URL")
        
        print(f"   â€¢ å­˜å‚¨ç±»å‹ç”±æœåŠ¡ç«¯é…ç½®å†³å®šï¼ˆSTORAGE_TYPE ç¯å¢ƒå˜é‡ï¼‰")
        print()
        print("ğŸ“‚ æœåŠ¡å™¨æœ¬åœ°æ–‡ä»¶ï¼ˆå¦‚éœ€è¦ï¼‰ï¼š")
        result_path = final_result.get('result_path')
        if result_path:
            print(f"   â€¢ å®Œæ•´ç»“æœè·¯å¾„: {result_path}")
            print(f"   â€¢ åŒ…å«: JSONã€Layout PDFã€åŸå§‹ PDF ç­‰")
            print(f"   â€¢ å¯é€šè¿‡æœåŠ¡å™¨ç›´æ¥è®¿é—®æˆ–ä½¿ç”¨å…¶ä»–æ–¹å¼ä¼ è¾“")
        print()
        
        # æ˜¾ç¤º Markdown é¢„è§ˆ
        print("ğŸ“„ Markdown å†…å®¹é¢„è§ˆï¼ˆå‰ 200 å­—ç¬¦ï¼‰ï¼š")
        print("-" * 60)
        
        # å¦‚æœä¸‹è½½äº†å›¾ç‰‡ï¼Œæ˜¾ç¤ºæ›´æ–°åçš„ Markdownï¼Œå¦åˆ™æ˜¾ç¤ºåŸå§‹çš„
        if images_downloaded > 0:
            with open(final_md_path, 'r', encoding='utf-8') as f:
                preview_content = f.read()
            preview = preview_content[:200]
            if len(preview_content) > 200:
                preview += "\n... (truncated)"
            print(f"(æ˜¾ç¤ºæœ¬åœ°å›¾ç‰‡ç‰ˆæœ¬)")
        else:
            preview = md_content[:200]
            if len(md_content) > 200:
                preview += "\n... (truncated)"
            if images_uploaded:
                print(f"(æ˜¾ç¤ºäº‘ç«¯å›¾ç‰‡é“¾æ¥ç‰ˆæœ¬)")
        
        print(preview)
        print()


if __name__ == "__main__":
    asyncio.run(main())

